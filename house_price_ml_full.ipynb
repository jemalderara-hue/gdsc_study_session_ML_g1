{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2894721f",
   "metadata": {},
   "source": [
    "# House Price Prediction — End-to-End Notebook\n",
    "\n",
    "This notebook performs an end-to-end house price prediction workflow:\n",
    "\n",
    "- Data loading & quick EDA\n",
    "- Preprocessing (categorical handling, missing values)\n",
    "- Train/test split\n",
    "- Train multiple models:\n",
    "  - Linear Regression\n",
    "  - Random Forest Regressor\n",
    "  - Gradient Boosting Regressor (from sklearn)\n",
    "  - XGBoost (if available)\n",
    "  - Support Vector Regressor (SVR)\n",
    "- Evaluation metrics: **MAE, MSE, RMSE, MRE (MAPE), R²**\n",
    "- Visualizations:\n",
    "  - Correlation heatmap\n",
    "  - Actual vs Predicted\n",
    "  - Residual plot\n",
    "  - Feature importance (tree-based)\n",
    "  - Distribution of prediction errors\n",
    "\n",
    "**Notes**\n",
    "- Expected dataset path: `'house price prediction dataset.zip/Housing.csv'`\n",
    "- If `price` column is named differently, change the `TARGET_COL` variable below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0c19a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Imports and helper functions\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "def mape(y_true, y_pred):\n",
    "    # Mean Absolute Percentage Error (used here as MRE)\n",
    "    # avoid division by zero by adding a tiny epsilon where y_true == 0\n",
    "    eps = 1e-8\n",
    "    y_true_safe = np.where(y_true == 0, eps, y_true)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true_safe)) * 100\n",
    "\n",
    "def evaluate_model(name, y_true, y_pred):\n",
    "    MAE = mean_absolute_error(y_true, y_pred)\n",
    "    MSE = mean_squared_error(y_true, y_pred)\n",
    "    RMSE = np.sqrt(MSE)\n",
    "    MRE = mape(y_true, y_pred)\n",
    "    R2 = r2_score(y_true, y_pred)\n",
    "    return {\"model\": name, \"MAE\": MAE, \"MSE\": MSE, \"RMSE\": RMSE, \"MRE(%)\": MRE, \"R2\": R2}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8a0689",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1) Load dataset\n",
    "DATA_PATH = 'house price prediction dataset.zip/Housing.csv'  # change if needed\n",
    "TARGET_COL = 'price'  # change if your target column has a different name\n",
    "\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    raise FileNotFoundError(f\"Dataset not found at {DATA_PATH}. Please upload the dataset to that path.\")\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"\\nColumns:\", df.columns.tolist())\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "display(df.head())\n",
    "\n",
    "print(\"\\nData types and non-null counts:\")\n",
    "display(df.info())\n",
    "\n",
    "print(\"\\nSummary statistics for numeric columns:\")\n",
    "display(df.describe(include=[np.number]).T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1f9f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2) Preprocessing\n",
    "# If the target column isn't present, try to guess common names\n",
    "if TARGET_COL not in df.columns:\n",
    "    possible = [c for c in df.columns if 'price' in c.lower()]\n",
    "    if len(possible) == 1:\n",
    "        TARGET_COL = possible[0]\n",
    "        print(f\"Using discovered target column: {TARGET_COL}\")\n",
    "    else:\n",
    "        raise ValueError(f\"Target column '{TARGET_COL}' not found. Found candidates: {possible}\")\n",
    "\n",
    "# Drop rows where target is missing\n",
    "df = df.dropna(subset=[TARGET_COL]).copy()\n",
    "\n",
    "# Encode categorical variables\n",
    "df_encoded = pd.get_dummies(df, drop_first=True)\n",
    "\n",
    "# Drop columns with too many missing values (optional)\n",
    "# For now, drop rows with any remaining NA\n",
    "df_encoded = df_encoded.dropna()\n",
    "\n",
    "print(\"After encoding and dropping NA, shape:\", df_encoded.shape)\n",
    "\n",
    "# Features and target\n",
    "X = df_encoded.drop(columns=[TARGET_COL])\n",
    "y = df_encoded[TARGET_COL].astype(float)\n",
    "\n",
    "# Save feature names for later use\n",
    "FEATURE_NAMES = X.columns.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afed4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3) Correlation heatmap (numeric features + target)\n",
    "corr = df_encoded.corr()\n",
    "# We'll show correlations of top correlated features with the target\n",
    "target_corr = corr[TARGET_COL].abs().sort_values(ascending=False)\n",
    "top_features = target_corr.index.tolist()[:20]  # pick top 20 for visualization\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.imshow(corr.loc[top_features, top_features], aspect='auto', interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.xticks(range(len(top_features)), top_features, rotation=90)\n",
    "plt.yticks(range(len(top_features)), top_features)\n",
    "plt.title('Correlation matrix (top features)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a60f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4) Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(\"Train shape:\", X_train.shape, \"Test shape:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b816d81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 5) Train multiple models\n",
    "models = {}\n",
    "\n",
    "# Linear Regression (no scaling required typically, but we'll add a pipeline in case)\n",
    "models['LinearRegression'] = make_pipeline(StandardScaler(), LinearRegression())\n",
    "\n",
    "# Random Forest\n",
    "models['RandomForest'] = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Gradient Boosting (sklearn)\n",
    "models['GradientBoosting'] = GradientBoostingRegressor(n_estimators=200, random_state=42)\n",
    "\n",
    "# HistGradientBoosting (fast alternative)\n",
    "models['HistGradientBoosting'] = HistGradientBoostingRegressor(random_state=42)\n",
    "\n",
    "# SVR (scale features)\n",
    "models['SVR'] = make_pipeline(StandardScaler(), SVR(C=1.0, epsilon=0.1))\n",
    "\n",
    "# Try to include XGBoost if available\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    models['XGBoost'] = xgb.XGBRegressor(n_estimators=200, random_state=42, verbosity=0)\n",
    "    print(\"XGBoost available and will be used.\")\n",
    "except Exception as e:\n",
    "    print(\"XGBoost not available in this environment - skipping XGBoost. Error:\", e)\n",
    "\n",
    "results = []\n",
    "fitted_models = {}\n",
    "\n",
    "for name, m in models.items():\n",
    "    print(f\"\\nTraining {name} ...\")\n",
    "    m.fit(X_train, y_train)\n",
    "    y_pred = m.predict(X_test)\n",
    "    res = evaluate_model(name, y_test, y_pred)\n",
    "    results.append(res)\n",
    "    fitted_models[name] = m\n",
    "    # store predictions for later analysis\n",
    "    if name == 'LinearRegression':\n",
    "        linear_pred = y_pred\n",
    "    if name == 'RandomForest':\n",
    "        rf_pred = y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d8d548",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 6) Results summary\n",
    "results_df = pd.DataFrame(results).sort_values(by='RMSE')\n",
    "results_df = results_df.reset_index(drop=True)\n",
    "from caas_jupyter_tools import display_dataframe_to_user\n",
    "display_dataframe_to_user(\"Model performance comparison\", results_df)\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3148c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 7) Visualizations for the best model (lowest RMSE)\n",
    "best_model_name = results_df.loc[0, 'model']\n",
    "best_model = fitted_models[best_model_name]\n",
    "print(\"Best model:\", best_model_name)\n",
    "\n",
    "y_best_pred = best_model.predict(X_test)\n",
    "\n",
    "# Actual vs Predicted scatter\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(y_test, y_best_pred)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], linewidth=2)  # 45-degree line\n",
    "plt.xlabel(\"Actual Prices\")\n",
    "plt.ylabel(\"Predicted Prices\")\n",
    "plt.title(f\"Actual vs Predicted — {best_model_name}\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Residual plot\n",
    "residuals = y_test - y_best_pred\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.scatter(y_best_pred, residuals)\n",
    "plt.axhline(0, linestyle='--', linewidth=2)\n",
    "plt.xlabel(\"Predicted Prices\")\n",
    "plt.ylabel(\"Residuals (Actual - Predicted)\")\n",
    "plt.title(f\"Residuals vs Predicted — {best_model_name}\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Distribution of residuals (errors)\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.hist(residuals, bins=40)\n",
    "plt.xlabel(\"Residual\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Distribution of Residuals\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a820d5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 8) Feature importance for tree-based models (if available)\n",
    "import numpy as _np\n",
    "\n",
    "def plot_feature_importance(model, model_name, top_n=20):\n",
    "    if hasattr(model, \"feature_importances_\"):\n",
    "        importances = model.feature_importances_\n",
    "        indices = _np.argsort(importances)[::-1][:top_n]\n",
    "        names = [FEATURE_NAMES[i] for i in indices]\n",
    "        vals = importances[indices]\n",
    "\n",
    "        plt.figure(figsize=(10,6))\n",
    "        plt.bar(range(len(vals)), vals)\n",
    "        plt.xticks(range(len(vals)), names, rotation=90)\n",
    "        plt.title(f\"Feature importances — {model_name} (top {top_n})\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"{model_name} does not expose feature_importances_\")\n",
    "\n",
    "# Try RandomForest, GradientBoosting, XGBoost\n",
    "for candidate in ['RandomForest', 'GradientBoosting', 'XGBoost', 'HistGradientBoosting']:\n",
    "    if candidate in fitted_models:\n",
    "        print(\"\\nFeature importance for:\", candidate)\n",
    "        try:\n",
    "            plot_feature_importance(fitted_models[candidate], candidate, top_n=20)\n",
    "        except Exception as e:\n",
    "            print(\"Could not plot feature importance for\", candidate, \":\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c7f4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 9) Save test predictions and model comparison\n",
    "pred_df = X_test.copy()\n",
    "pred_df['Actual'] = y_test\n",
    "for name, model in fitted_models.items():\n",
    "    pred_df[f'Pred_{name}'] = model.predict(X_test)\n",
    "\n",
    "predictions_file = '/mnt/data/house_price_predictions.csv'\n",
    "pred_df.to_csv(predictions_file, index=True)\n",
    "print(\"Saved predictions to:\", predictions_file)\n",
    "\n",
    "# Save results_df\n",
    "results_file = '/mnt/data/model_comparison_results.csv'\n",
    "results_df.to_csv(results_file, index=False)\n",
    "print(\"Saved model comparison results to:\", results_file)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
